{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from flaxdiff.schedulers import EDMNoiseScheduler, KarrasVENoiseScheduler\n",
    "from flaxdiff.predictors import KarrasPredictionTransform\n",
    "from flaxdiff.models.simple_unet import Unet\n",
    "from flaxdiff.trainer.general_diffusion_trainer import GeneralDiffusionTrainer, ConditionalInputConfig\n",
    "from flaxdiff.data.dataloaders import get_dataset_grain\n",
    "from flaxdiff.utils import defaultTextEncodeModel, get_latest_checkpoint\n",
    "from flaxdiff.models.autoencoder.diffusers import StableDiffusionVAE\n",
    "from flaxdiff.samplers.euler import EulerAncestralSampler\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "IMAGE_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 23:28:30.208084: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746142110.230913  230314 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746142110.237860  230314 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746142110.254208  230314 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746142110.254225  230314 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746142110.254227  230314 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746142110.254229  230314 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "Some weights of the model checkpoint at openai/clip-vit-large-patch14 were not used when initializing FlaxCLIPTextModel: {('vision_model', 'encoder', 'layers', '22', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '17', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '14', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '0', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '15', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '10', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '11', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '11', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '15', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '8', 'mlp', 'fc2', 'kernel'), ('visual_projection', 'kernel'), ('vision_model', 'encoder', 'layers', '22', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '5', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '0', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '11', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '15', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '20', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '14', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '7', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '23', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '3', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '21', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '6', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '1', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '12', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '17', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '12', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '1', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '7', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '1', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '3', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '15', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '12', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '17', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '23', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '3', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '10', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'pre_layrnorm', 'bias'), ('vision_model', 'encoder', 'layers', '17', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '12', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '5', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '23', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '11', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '8', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '8', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '3', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '9', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '6', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '6', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '13', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '0', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '8', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '1', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '11', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '18', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '2', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '9', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '19', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '17', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '5', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '16', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '21', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '21', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '1', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '20', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '7', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '5', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '2', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '16', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '2', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '4', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '23', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '4', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '21', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '2', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '3', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '9', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '21', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '5', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '0', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '7', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '2', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '14', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '1', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '3', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '11', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '21', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '12', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '0', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '14', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '18', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '23', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '14', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '9', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '21', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '20', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '20', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '21', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '11', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '16', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '11', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '20', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '20', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '15', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '5', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '18', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '10', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '12', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '4', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '15', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '5', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '5', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '8', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '10', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '14', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '8', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '12', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '13', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '23', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '0', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '6', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '20', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '13', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '23', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '20', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '5', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '20', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '6', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '23', 'mlp', 'fc2', 'kernel'), ('vision_model', 'embeddings', 'patch_embedding', 'kernel'), ('vision_model', 'encoder', 'layers', '6', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '16', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '7', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '21', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '1', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '20', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '2', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '2', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '23', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '9', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '15', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '18', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '13', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '16', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '21', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '9', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '16', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '2', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '23', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '1', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '10', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '6', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '20', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '19', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '5', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '9', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '18', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '16', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '1', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '18', 'layer_norm2', 'bias'), ('vision_model', 'post_layernorm', 'bias'), ('vision_model', 'encoder', 'layers', '22', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '9', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '13', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '0', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '9', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '19', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '11', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '18', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '11', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '2', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '8', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '4', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '21', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '19', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '0', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '16', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '7', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '18', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '21', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '7', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '18', 'self_attn', 'v_proj', 'bias'), ('text_projection', 'kernel'), ('vision_model', 'encoder', 'layers', '17', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '15', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '14', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '7', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '3', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '2', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '4', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '7', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '3', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '1', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '10', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '22', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '0', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '15', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '12', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '14', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '4', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '23', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '22', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '20', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '2', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '10', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '4', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '23', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '18', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '20', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '7', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '18', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '13', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '15', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '13', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '19', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '18', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '17', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '18', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '6', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '5', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '13', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '20', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '11', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '17', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '10', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '14', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '2', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '17', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '23', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '5', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '15', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '9', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '2', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '4', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '6', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '22', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '23', 'mlp', 'fc1', 'kernel'), ('logit_scale',), ('vision_model', 'encoder', 'layers', '12', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '16', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '19', 'mlp', 'fc1', 'bias'), ('vision_model', 'embeddings', 'position_embedding', 'embedding'), ('vision_model', 'encoder', 'layers', '9', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '9', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '17', 'layer_norm1', 'scale'), ('vision_model', 'embeddings', 'class_embedding'), ('vision_model', 'encoder', 'layers', '13', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '21', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '16', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '12', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '9', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '6', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '3', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '3', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '9', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '4', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '2', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '3', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '22', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '13', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '0', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '19', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '8', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '13', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '5', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '7', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '6', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '1', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '22', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '16', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '22', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '14', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '8', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '19', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '8', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '8', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '22', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '5', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '19', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '21', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '22', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '15', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '19', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '16', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '12', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '16', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '3', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '22', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '11', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '7', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '18', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '10', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '0', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '17', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '17', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '14', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '6', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '2', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '15', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '3', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '14', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '19', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '11', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '4', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '9', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '15', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '10', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '0', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '10', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '17', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '5', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '14', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '6', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '17', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '15', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '12', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '4', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '22', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '9', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '23', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '10', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '10', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '5', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '2', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '10', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '17', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '13', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '20', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '6', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '18', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '8', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '13', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '19', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '13', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '14', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '19', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '21', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '22', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '18', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '20', 'self_attn', 'k_proj', 'bias'), ('vision_model', 'encoder', 'layers', '1', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '11', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '13', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '12', 'layer_norm1', 'scale'), ('vision_model', 'encoder', 'layers', '1', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '13', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '10', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '4', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '4', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '3', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '16', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '7', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '0', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '1', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '8', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '22', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'post_layernorm', 'scale'), ('vision_model', 'pre_layrnorm', 'scale'), ('vision_model', 'encoder', 'layers', '3', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '11', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '7', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '6', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '19', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '12', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '1', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '0', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '8', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '19', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '8', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '22', 'self_attn', 'v_proj', 'bias'), ('vision_model', 'encoder', 'layers', '14', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '12', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '6', 'self_attn', 'out_proj', 'bias'), ('vision_model', 'encoder', 'layers', '16', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '21', 'self_attn', 'out_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '16', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '0', 'layer_norm2', 'scale'), ('vision_model', 'encoder', 'layers', '4', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '10', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '8', 'mlp', 'fc1', 'bias'), ('vision_model', 'encoder', 'layers', '12', 'mlp', 'fc2', 'kernel'), ('vision_model', 'encoder', 'layers', '3', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '14', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '19', 'layer_norm1', 'bias'), ('vision_model', 'encoder', 'layers', '17', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '0', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '4', 'self_attn', 'q_proj', 'bias'), ('vision_model', 'encoder', 'layers', '15', 'mlp', 'fc1', 'kernel'), ('vision_model', 'encoder', 'layers', '11', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '7', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '4', 'mlp', 'fc2', 'bias'), ('vision_model', 'encoder', 'layers', '7', 'layer_norm2', 'bias'), ('vision_model', 'encoder', 'layers', '1', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'encoder', 'layers', '23', 'layer_norm2', 'scale')}\n",
      "- This IS expected if you are initializing FlaxCLIPTextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FlaxCLIPTextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling factor: 0.18215\n",
      "Calculating downscale factor...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m batches = datalen // BATCH_SIZE\n\u001b[32m      7\u001b[39m text_encoder = defaultTextEncodeModel()\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m autoencoder = \u001b[43mStableDiffusionVAE\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodelname\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpcuenq/sd-vae-ft-mse-flax\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Construct a validation set by the prompts\u001b[39;00m\n\u001b[32m     11\u001b[39m val_prompts = [\u001b[33m'\u001b[39m\u001b[33mwater tulip\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a water lily\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a water lily\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a photo of a rose\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a photo of a rose\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a water lily\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a water lily\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a photo of a marigold\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a photo of a marigold\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a photo of a marigold\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a water lily\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a photo of a sunflower\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a photo of a lotus\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m columbine\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m columbine\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m an orchid\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m an orchid\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m an orchid\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a water lily\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a water lily\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a water lily\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m columbine\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m columbine\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a photo of a sunflower\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a photo of a sunflower\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a photo of a sunflower\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a photo of a lotus\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a photo of a lotus\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a photo of a marigold\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a photo of a marigold\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a photo of a rose\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a photo of a rose\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a photo of a rose\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     12\u001b[39m                \u001b[33m'\u001b[39m\u001b[33m orange dahlia\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m orange dahlia\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a lenten rose\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a lenten rose\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a water lily\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a water lily\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a water lily\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a water lily\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m an orchid\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m an orchid\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m an orchid\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m hard-leaved pocket orchid\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m bird of paradise\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m bird of paradise\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a photo of a lovely rose\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a photo of a lovely rose\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a photo of a globe-flower\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a photo of a globe-flower\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a photo of a lovely rose\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a photo of a lovely rose\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a photo of a ruby-lipped cattleya\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a photo of a ruby-lipped cattleya\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a photo of a lovely rose\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a water lily\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a osteospermum\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a osteospermum\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a water lily\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a water lily\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a water lily\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a red rose\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m a red rose\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flaxdiff/lib/python3.12/site-packages/flaxdiff/models/autoencoder/diffusers.py:95\u001b[39m, in \u001b[36mStableDiffusionVAE.__init__\u001b[39m\u001b[34m(self, modelname, revision, dtype)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCalculating downscale factor...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     94\u001b[39m dummy_input = jnp.ones((\u001b[32m1\u001b[39m, \u001b[32m128\u001b[39m, \u001b[32m128\u001b[39m, \u001b[32m3\u001b[39m), dtype=dtype)\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m dummy_latents = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode_single_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m _, h, w, c = dummy_latents.shape\n\u001b[32m     97\u001b[39m _, H, W, C = dummy_input.shape\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flaxdiff/lib/python3.12/site-packages/jax/_src/pjit.py:339\u001b[39m, in \u001b[36m_cpp_pjit.<locals>.cache_miss\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config.no_tracing.value:\n\u001b[32m    335\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mre-tracing function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjit_info.fun_sourceinfo\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    336\u001b[39m                      \u001b[33m\"\u001b[39m\u001b[33m`jit`, but \u001b[39m\u001b[33m'\u001b[39m\u001b[33mno_tracing\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is set\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    338\u001b[39m (outs, out_flat, out_tree, args_flat, jaxpr, attrs_tracked, executable,\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m  pgle_profiler) = \u001b[43m_python_pjit_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjit_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    341\u001b[39m maybe_fastpath_data = _get_fastpath_data(\n\u001b[32m    342\u001b[39m     executable, out_tree, args_flat, out_flat, attrs_tracked, jaxpr.effects,\n\u001b[32m    343\u001b[39m     jaxpr.consts, jit_info.abstracted_axes,\n\u001b[32m    344\u001b[39m     pgle_profiler)\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m outs, maybe_fastpath_data, _need_to_rebuild_with_fdo(pgle_profiler)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flaxdiff/lib/python3.12/site-packages/jax/_src/pjit.py:194\u001b[39m, in \u001b[36m_python_pjit_helper\u001b[39m\u001b[34m(fun, jit_info, *args, **kwargs)\u001b[39m\n\u001b[32m    192\u001b[39m   args_flat = \u001b[38;5;28mmap\u001b[39m(core.full_lower, args_flat)\n\u001b[32m    193\u001b[39m   core.check_eval_args(args_flat)\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m   out_flat, compiled, profiler = \u001b[43m_pjit_call_impl_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    196\u001b[39m   out_flat = pjit_p.bind(*args_flat, **p.params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flaxdiff/lib/python3.12/site-packages/jax/_src/pjit.py:1659\u001b[39m, in \u001b[36m_pjit_call_impl_python\u001b[39m\u001b[34m(jaxpr, in_shardings, out_shardings, in_layouts, out_layouts, donated_invars, ctx_mesh, name, keep_unused, inline, compiler_options_kvs, *args)\u001b[39m\n\u001b[32m   1647\u001b[39m compiler_options_kvs = compiler_options_kvs + \u001b[38;5;28mtuple\u001b[39m(pgle_compile_options.items())\n\u001b[32m   1648\u001b[39m \u001b[38;5;66;03m# Passing mutable PGLE profile here since it should be extracted by JAXPR to\u001b[39;00m\n\u001b[32m   1649\u001b[39m \u001b[38;5;66;03m# initialize the fdo_profile compile option.\u001b[39;00m\n\u001b[32m   1650\u001b[39m compiled = \u001b[43m_resolve_and_lower\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1651\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_shardings\u001b[49m\u001b[43m=\u001b[49m\u001b[43min_shardings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1652\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_layouts\u001b[49m\u001b[43m=\u001b[49m\u001b[43min_layouts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1653\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout_layouts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout_layouts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1654\u001b[39m \u001b[43m    \u001b[49m\u001b[43mctx_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mctx_mesh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_unused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1655\u001b[39m \u001b[43m    \u001b[49m\u001b[43minline\u001b[49m\u001b[43m=\u001b[49m\u001b[43minline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlowering_platforms\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1656\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlowering_parameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmlir\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLoweringParameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1657\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpgle_profiler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpgle_profiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1658\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiler_options_kvs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompiler_options_kvs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m1659\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1661\u001b[39m \u001b[38;5;66;03m# This check is expensive so only do it if enable_checks is on.\u001b[39;00m\n\u001b[32m   1662\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compiled._auto_spmd_lowering \u001b[38;5;129;01mand\u001b[39;00m config.enable_checks.value:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flaxdiff/lib/python3.12/site-packages/jax/_src/interpreters/pxla.py:2448\u001b[39m, in \u001b[36mMeshComputation.compile\u001b[39m\u001b[34m(self, compiler_options)\u001b[39m\n\u001b[32m   2446\u001b[39m compiler_options_kvs = \u001b[38;5;28mself\u001b[39m._compiler_options_kvs + t_compiler_options\n\u001b[32m   2447\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._executable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m compiler_options_kvs:\n\u001b[32m-> \u001b[39m\u001b[32m2448\u001b[39m   executable = \u001b[43mUnloadedMeshExecutable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_hlo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2449\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_hlo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompile_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2450\u001b[39m \u001b[43m      \u001b[49m\u001b[43mcompiler_options_kvs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompiler_options_kvs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2451\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m compiler_options_kvs:\n\u001b[32m   2452\u001b[39m     \u001b[38;5;28mself\u001b[39m._executable = executable\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flaxdiff/lib/python3.12/site-packages/jax/_src/interpreters/pxla.py:2967\u001b[39m, in \u001b[36mUnloadedMeshExecutable.from_hlo\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   2964\u001b[39m       \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   2966\u001b[39m util.test_event(\u001b[33m\"\u001b[39m\u001b[33mpxla_cached_compilation\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2967\u001b[39m xla_executable = \u001b[43m_cached_compilation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhlo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmesh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspmd_lowering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2969\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtuple_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauto_spmd_lowering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_prop_to_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2970\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_prop_to_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhost_callbacks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpmap_nreps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiler_options_kvs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpgle_profiler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2973\u001b[39m orig_out_shardings = out_shardings\n\u001b[32m   2975\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m auto_spmd_lowering:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flaxdiff/lib/python3.12/site-packages/jax/_src/interpreters/pxla.py:2758\u001b[39m, in \u001b[36m_cached_compilation\u001b[39m\u001b[34m(computation, name, mesh, spmd_lowering, tuple_args, auto_spmd_lowering, allow_prop_to_inputs, allow_prop_to_outputs, host_callbacks, backend, da, pmap_nreps, compiler_options_kvs, pgle_profiler)\u001b[39m\n\u001b[32m   2750\u001b[39m compile_options = create_compile_options(\n\u001b[32m   2751\u001b[39m     computation, mesh, spmd_lowering, tuple_args, auto_spmd_lowering,\n\u001b[32m   2752\u001b[39m     allow_prop_to_inputs, allow_prop_to_outputs, backend,\n\u001b[32m   2753\u001b[39m     dev, pmap_nreps, compiler_options)\n\u001b[32m   2755\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m dispatch.log_elapsed_time(\n\u001b[32m   2756\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mFinished XLA compilation of \u001b[39m\u001b[38;5;132;01m{fun_name}\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m{elapsed_time:.9f}\u001b[39;00m\u001b[33m sec\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2757\u001b[39m     fun_name=name, event=dispatch.BACKEND_COMPILE_EVENT):\n\u001b[32m-> \u001b[39m\u001b[32m2758\u001b[39m   xla_executable = \u001b[43mcompiler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile_or_get_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2759\u001b[39m \u001b[43m      \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomputation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost_callbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2760\u001b[39m \u001b[43m      \u001b[49m\u001b[43mpgle_profiler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2761\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m xla_executable\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flaxdiff/lib/python3.12/site-packages/jax/_src/compiler.py:470\u001b[39m, in \u001b[36mcompile_or_get_cached\u001b[39m\u001b[34m(backend, computation, devices, compile_options, host_callbacks, pgle_profiler)\u001b[39m\n\u001b[32m    468\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    469\u001b[39m   log_persistent_cache_miss(module_name, cache_key)\n\u001b[32m--> \u001b[39m\u001b[32m470\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile_and_write_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m      \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m      \u001b[49m\u001b[43mcomputation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m      \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m      \u001b[49m\u001b[43mhost_callbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m      \u001b[49m\u001b[43mcache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flaxdiff/lib/python3.12/site-packages/jax/_src/compiler.py:687\u001b[39m, in \u001b[36m_compile_and_write_cache\u001b[39m\u001b[34m(backend, computation, compile_options, host_callbacks, module_name, cache_key)\u001b[39m\n\u001b[32m    678\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_compile_and_write_cache\u001b[39m(\n\u001b[32m    679\u001b[39m     backend: xc.Client,\n\u001b[32m    680\u001b[39m     computation: ir.Module,\n\u001b[32m   (...)\u001b[39m\u001b[32m    684\u001b[39m     cache_key: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    685\u001b[39m ) -> xc.LoadedExecutable:\n\u001b[32m    686\u001b[39m   start_time = time.monotonic()\n\u001b[32m--> \u001b[39m\u001b[32m687\u001b[39m   executable = \u001b[43mbackend_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m      \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomputation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost_callbacks\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    690\u001b[39m   compile_time = time.monotonic() - start_time\n\u001b[32m    691\u001b[39m   _cache_write(\n\u001b[32m    692\u001b[39m       cache_key, compile_time, module_name, backend, executable, host_callbacks\n\u001b[32m    693\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flaxdiff/lib/python3.12/site-packages/jax/_src/profiler.py:334\u001b[39m, in \u001b[36mannotate_function.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    331\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    333\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, **decorator_kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    335\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flaxdiff/lib/python3.12/site-packages/jax/_src/compiler.py:321\u001b[39m, in \u001b[36mbackend_compile\u001b[39m\u001b[34m(backend, module, options, host_callbacks)\u001b[39m\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m backend.compile(\n\u001b[32m    316\u001b[39m         built_c, compile_options=options, host_callbacks=host_callbacks\n\u001b[32m    317\u001b[39m     )\n\u001b[32m    318\u001b[39m   \u001b[38;5;66;03m# Some backends don't have `host_callbacks` option yet\u001b[39;00m\n\u001b[32m    319\u001b[39m   \u001b[38;5;66;03m# TODO(sharadmv): remove this fallback when all backends allow `compile`\u001b[39;00m\n\u001b[32m    320\u001b[39m   \u001b[38;5;66;03m# to take in `host_callbacks`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilt_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m xc.XlaRuntimeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    323\u001b[39m   \u001b[38;5;28;01mfor\u001b[39;00m error_handler \u001b[38;5;129;01min\u001b[39;00m _XLA_RUNTIME_ERROR_HANDLERS:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "data = get_dataset_grain(\n",
    "    \"oxford_flowers102\", batch_size=BATCH_SIZE, image_scale=IMAGE_SIZE)\n",
    "datalen = data['train_len']\n",
    "batches = datalen // BATCH_SIZE\n",
    "\n",
    "text_encoder = defaultTextEncodeModel()\n",
    "autoencoder = StableDiffusionVAE(**{\"modelname\": \"pcuenq/sd-vae-ft-mse-flax\"})\n",
    "\n",
    "# Construct a validation set by the prompts\n",
    "val_prompts = ['water tulip', ' a water lily', ' a water lily', ' a photo of a rose', ' a photo of a rose', ' a water lily', ' a water lily', ' a photo of a marigold', ' a photo of a marigold', ' a photo of a marigold', ' a water lily', ' a photo of a sunflower', ' a photo of a lotus', ' columbine', ' columbine', ' an orchid', ' an orchid', ' an orchid', ' a water lily', ' a water lily', ' a water lily', ' columbine', ' columbine', ' a photo of a sunflower', ' a photo of a sunflower', ' a photo of a sunflower', ' a photo of a lotus', ' a photo of a lotus', ' a photo of a marigold', ' a photo of a marigold', ' a photo of a rose', ' a photo of a rose', ' a photo of a rose',\n",
    "               ' orange dahlia', ' orange dahlia', ' a lenten rose', ' a lenten rose', ' a water lily', ' a water lily', ' a water lily', ' a water lily', ' an orchid', ' an orchid', ' an orchid', ' hard-leaved pocket orchid', ' bird of paradise', ' bird of paradise', ' a photo of a lovely rose', ' a photo of a lovely rose', ' a photo of a globe-flower', ' a photo of a globe-flower', ' a photo of a lovely rose', ' a photo of a lovely rose', ' a photo of a ruby-lipped cattleya', ' a photo of a ruby-lipped cattleya', ' a photo of a lovely rose', ' a water lily', ' a osteospermum', ' a osteospermum', ' a water lily', ' a water lily', ' a water lily', ' a red rose', ' a red rose']\n",
    "\n",
    "\n",
    "def get_val_dataset(batch_size=8):\n",
    "    for i in range(0, len(val_prompts), batch_size):\n",
    "        prompts = val_prompts[i:i + batch_size]\n",
    "        tokens = text_encoder.tokenize(prompts)\n",
    "        yield {\"text\": tokens}\n",
    "\n",
    "\n",
    "data['test'] = get_val_dataset\n",
    "data['test_len'] = len(val_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated input shapes: {'x': (32, 32, 4), 'temb': (), 'textcontext': (77, 768)}\n"
     ]
    }
   ],
   "source": [
    "from flax import linen as nn\n",
    "from diffusers import FlaxUNet2DConditionModel\n",
    "from flaxdiff.inputs import DiffusionInputConfig, ConditionalInputConfig\n",
    "\n",
    "input_config = DiffusionInputConfig(\n",
    "    sample_data_key='image',\n",
    "    sample_data_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "    conditions=[\n",
    "        ConditionalInputConfig(\n",
    "            encoder=text_encoder,\n",
    "            conditioning_data_key='text',\n",
    "            pretokenized=True,\n",
    "            unconditional_input=\"\",\n",
    "            model_key_override=\"textcontext\",\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "input_shapes = input_config.get_input_shapes(\n",
    "    autoencoder=autoencoder,\n",
    ")\n",
    "\n",
    "unet_model = FlaxUNet2DConditionModel(\n",
    "    sample_size=input_shapes[\"x\"][1],  # the target image resolution\n",
    "    # the number of input channels, 3 for RGB images\n",
    "    in_channels=input_shapes[\"x\"][2],\n",
    "    out_channels=input_shapes[\"x\"][2],  # the number of output channels\n",
    "    layers_per_block=2,  # how many ResNet layers to use per UNet block\n",
    "    # the number of output channels for each UNet block\n",
    "    block_out_channels=(64, 128, 256, 512),\n",
    "    cross_attention_dim=512,  # the size of the cross-attention layers\n",
    "    dtype=jnp.bfloat16,\n",
    "    use_memory_efficient_attention=True,\n",
    ")\n",
    "\n",
    "\n",
    "class BCHWModelWrapper(nn.Module):\n",
    "    model: nn.Module\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, temb, textcontext):\n",
    "        # Reshape the input to BCHW format from BHWC\n",
    "        x = jnp.transpose(x, (0, 3, 1, 2))\n",
    "        # Pass the input through the UNet model\n",
    "        out = self.model(\n",
    "            sample=x,\n",
    "            timesteps=temb,\n",
    "            encoder_hidden_states=textcontext,\n",
    "        )\n",
    "        # Reshape the output back to BHWC format\n",
    "        out = jnp.transpose(out.sample, (0, 2, 3, 1))\n",
    "        return out\n",
    "    \n",
    "    @property\n",
    "    def __dict__(self):\n",
    "        return self.model.__dict__\n",
    "\n",
    "unet = BCHWModelWrapper(unet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated input shapes: {'x': (32, 32, 4), 'temb': (), 'textcontext': (77, 768)}\n"
     ]
    }
   ],
   "source": [
    "from flaxdiff.inputs import DiffusionInputConfig, ConditionalInputConfig\n",
    "\n",
    "input_config = DiffusionInputConfig(\n",
    "    sample_data_key='image',\n",
    "    sample_data_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "    conditions=[\n",
    "        ConditionalInputConfig(\n",
    "            encoder=text_encoder,\n",
    "            conditioning_data_key='text',\n",
    "            pretokenized=True,\n",
    "            unconditional_input=\"\",\n",
    "            model_key_override=\"textcontext\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "input_shapes = input_config.get_input_shapes(\n",
    "    autoencoder=autoencoder,\n",
    ")\n",
    "\n",
    "unet = Unet(emb_features=256,\n",
    "            feature_depths=[64, 64, 128, 256, 512],\n",
    "            attention_configs=[\n",
    "                None,\n",
    "                {\"heads\": 8, \"dtype\": jnp.float32, \"flash_attention\": False,\n",
    "                    \"use_projection\": False, \"use_self_and_cross\": True},\n",
    "                {\"heads\": 8, \"dtype\": jnp.float32, \"flash_attention\": False,\n",
    "                    \"use_projection\": False, \"use_self_and_cross\": True},\n",
    "                {\"heads\": 8, \"dtype\": jnp.float32, \"flash_attention\": False,\n",
    "                    \"use_projection\": False, \"use_self_and_cross\": True},\n",
    "                {\"heads\": 8, \"dtype\": jnp.float32, \"flash_attention\": False,\n",
    "                    \"use_projection\": False, \"use_self_and_cross\": False}\n",
    "            ],\n",
    "            num_res_blocks=2,\n",
    "            num_middle_res_blocks=1,\n",
    "            dtype=jnp.bfloat16,\n",
    "            output_channels=input_shapes[\"x\"][2],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated input shapes: {'x': (32, 32, 4), 'temb': (), 'textcontext': (77, 768)}\n",
      "Model name: diffusion-oxford_flowers102-res256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mashishkumar4\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mrwhite0racle/persist/FlaxDiff/wandb/run-20250419_153720-4b2mer47</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/umd-projects/mlops-msml605-project/runs/4b2mer47' target=\"_blank\">General_Diffusion_demo_for_inference2</a></strong> to <a href='https://wandb.ai/umd-projects/mlops-msml605-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/umd-projects/mlops-msml605-project' target=\"_blank\">https://wandb.ai/umd-projects/mlops-msml605-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/umd-projects/mlops-msml605-project/runs/4b2mer47' target=\"_blank\">https://wandb.ai/umd-projects/mlops-msml605-project/runs/4b2mer47</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Configured `CheckpointManager` using deprecated legacy API. Please follow the instructions at https://orbax.readthedocs.io/en/latest/api_refactor.html to migrate.\n",
      "WARNING:absl:Configured `CheckpointManager` using deprecated legacy API. Please follow the instructions at https://orbax.readthedocs.io/en/latest/api_refactor.html to migrate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from checkpoint at step  411355\n",
      "Loaded model from checkpoint at epoch 804 step 411355 0.4702588\n",
      "Generating states for DiffusionTrainer\n"
     ]
    }
   ],
   "source": [
    "# Define noise scheduler\n",
    "edm_schedule = EDMNoiseScheduler(1, sigma_max=80, rho=7, sigma_data=0.5)\n",
    "karas_ve_schedule = KarrasVENoiseScheduler(\n",
    "    1, sigma_max=80, rho=7, sigma_data=0.5)\n",
    "# Define model\n",
    "\n",
    "# Define optimizer\n",
    "solver = optax.adam(2e-4)\n",
    "\n",
    "# Create the GeneralDiffusionTrainer\n",
    "experiment_name = \"General_Diffusion_2025-04-18_06:34:50\"#f\"General_Diffusion_{datetime.now().strftime('%Y-%m-%d_%H:%M:%S')}\"\n",
    "\n",
    "trainer = GeneralDiffusionTrainer(\n",
    "    unet,\n",
    "    optimizer=solver,\n",
    "    noise_schedule=edm_schedule,\n",
    "    autoencoder=autoencoder,\n",
    "    input_config=input_config,\n",
    "    rngs=jax.random.PRNGKey(42),\n",
    "    name=experiment_name,\n",
    "    model_output_transform=KarrasPredictionTransform(\n",
    "        sigma_data=edm_schedule.sigma_data),\n",
    "    # data_key='image',  # Specify the key for image data in batches\n",
    "    distributed_training=True,\n",
    "    wandb_config={\n",
    "        \"project\": 'mlops-msml605-project',\n",
    "        \"entity\": 'umd-projects',\n",
    "        \"name\": experiment_name,\n",
    "        \"id\": \"bdw4ebqf\",\n",
    "        \"config\": {\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"image_size\": IMAGE_SIZE,\n",
    "            \"arguments\": {\n",
    "                \"architecture\": \"unet\",\n",
    "                \"dataset\": \"oxford_flowers102\",\n",
    "                \"noise_schedule\": \"edm\",\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    native_resolution=IMAGE_SIZE,\n",
    "    # Path to the checkpoint\n",
    "    load_from_checkpoint=\"/home/mrwhite0racle/persist/FlaxDiff/checkpoints/general_diffusion_2025-04-18_06:34:50\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 897: 600step [00:31, 19.01step/s, loss=0.4680]                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 897 Loss: 0.47235533595085144\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 897 completed. Avg Loss: 0.47235533595085144, Time: 31.57s, Best Loss: 0.47025880217552185\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 105.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 898/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 898:   0%|                                           | 0/511 [00:00<?, ?step/s, loss=0.4724]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 458878\n",
      "Training started for process index 0 at step 458878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 898: 600step [00:30, 19.66step/s, loss=0.4214]                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 898 Loss: 0.4722280502319336\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 898 completed. Avg Loss: 0.4722280502319336, Time: 30.52s, Best Loss: 0.47025880217552185\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 104.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 899/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 899:   0%|                                           | 0/511 [00:00<?, ?step/s, loss=0.4720]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 459389\n",
      "Training started for process index 0 at step 459389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 899: 600step [00:30, 19.51step/s, loss=0.5028]                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 899 Loss: 0.473550945520401\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 899 completed. Avg Loss: 0.473550945520401, Time: 30.75s, Best Loss: 0.47025880217552185\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 104.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 900/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 900:   0%|                                           | 0/511 [00:00<?, ?step/s, loss=0.5043]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 459900\n",
      "Training started for process index 0 at step 459900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 900: 600step [00:30, 19.69step/s, loss=0.4644]                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 900 Loss: 0.47377240657806396\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 900 completed. Avg Loss: 0.47377240657806396, Time: 30.48s, Best Loss: 0.47025880217552185\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 101.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 901/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 901:   0%|                                           | 0/511 [00:00<?, ?step/s, loss=0.4685]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 460411\n",
      "Training started for process index 0 at step 460411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 901: 600step [00:31, 19.08step/s, loss=0.4860]                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 901 Loss: 0.47391751408576965\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 901 completed. Avg Loss: 0.47391751408576965, Time: 31.45s, Best Loss: 0.47025880217552185\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 100.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 902/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 902:   0%|                                           | 0/511 [00:00<?, ?step/s, loss=0.4568]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 460922\n",
      "Training started for process index 0 at step 460922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 902: 600step [00:31, 18.90step/s, loss=0.4688]                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch done on index 0 => 902 Loss: 0.47201600670814514\u001b[0m\n",
      "\u001b[32mEpoch done on process index 0\u001b[0m\n",
      "\u001b[32m\n",
      "\tEpoch 902 completed. Avg Loss: 0.47201600670814514, Time: 31.75s, Best Loss: 0.47025880217552185\u001b[0m\n",
      "Validation started for process index 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 200/200 [00:01<00:00, 100.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mValidation done on process index 0\u001b[0m\n",
      "\n",
      "Epoch 903/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tEpoch 903:   0%|                                           | 0/511 [00:00<?, ?step/s, loss=0.4279]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch loaded at step 461433\n",
      "Training started for process index 0 at step 461433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnProcess-29:\n",
      "Process SpawnProcess-32:\n",
      "Process SpawnProcess-15:\n",
      "Process SpawnProcess-18:\n",
      "Process SpawnProcess-10:\n",
      "Process SpawnProcess-31:\n",
      "Process SpawnProcess-21:\n",
      "Process SpawnProcess-6:\n",
      "Process SpawnProcess-16:\n",
      "Process SpawnProcess-27:\n",
      "Process SpawnProcess-9:\n",
      "Process SpawnProcess-4:\n",
      "Process SpawnProcess-25:\n",
      "Process SpawnProcess-7:\n",
      "Process SpawnProcess-23:\n",
      "Process SpawnProcess-11:\n",
      "Process SpawnProcess-28:\n",
      "Process SpawnProcess-12:\n",
      "Process SpawnProcess-30:\n",
      "Process SpawnProcess-19:\n",
      "Process SpawnProcess-2:\n",
      "Process SpawnProcess-5:\n",
      "Process SpawnProcess-8:\n",
      "Process SpawnProcess-14:\n",
      "Process SpawnProcess-24:\n",
      "Process SpawnProcess-26:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process SpawnProcess-3:\n",
      "Process SpawnProcess-20:\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Process SpawnProcess-22:\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process SpawnProcess-17:\n",
      "Process SpawnProcess-13:\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Process SpawnProcess-1:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 235, in _worker_loop\n",
      "    next_element = next(element_producer)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/data_loader.py\", line 387, in __call__\n",
      "    yield from self._read_and_transform_data(last_seen_index)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/data_loader.py\", line 528, in _apply_transform\n",
      "    for input_record in input_iterator:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/data_loader.py\", line 518, in _apply_transform\n",
      "    for r in batch_op(input_iterator):\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/operations.py\", line 152, in __call__\n",
      "    for input_record in input_iterator:\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/data_loader.py\", line 530, in _apply_transform\n",
      "    output_record, filter_result = fn(input_record)\n",
      "                                   ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/data_loader.py\", line 497, in <lambda>\n",
      "    fn = lambda r: (record.Record(r.metadata, transform.map(r.data)), True)\n",
      "                                              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/persist/FlaxDiff/flaxdiff/data/sources/images.py\", line 159, in map\n",
      "    results = self.tokenize(caption)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/persist/FlaxDiff/flaxdiff/utils.py\", line 166, in __call__\n",
      "    tokens = self.tokenizer(inputs, padding=\"max_length\", max_length=self.tokenizer.model_max_length,\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/transformers/tokenization_utils_base.py\", line 2887, in __call__\n",
      "    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/transformers/tokenization_utils_base.py\", line 2997, in _call_one\n",
      "    return self.encode_plus(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/transformers/tokenization_utils_base.py\", line 3073, in encode_plus\n",
      "    return self._encode_plus(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/transformers/tokenization_utils_fast.py\", line 613, in _encode_plus\n",
      "    batched_output = self._batch_encode_plus(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/transformers/tokenization_utils_fast.py\", line 539, in _batch_encode_plus\n",
      "    encodings = self._tokenizer.encode_batch(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/grain_pool.py\", line 236, in _worker_loop\n",
      "    if not multiprocessing_common.add_element_to_queue(  # pytype: disable=wrong-arg-types\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/grain/_src/python/multiprocessing_common.py\", line 54, in add_element_to_queue\n",
      "    elements_queue.put(element, timeout=_QUEUE_WAIT_TIMEOUT_SECONDS)\n",
      "  File \"/home/mrwhite0racle/miniconda3/envs/flaxdiff/lib/python3.11/multiprocessing/queues.py\", line 89, in put\n",
      "    if not self._sem.acquire(block, timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m final_state = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampler_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEulerAncestralSampler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_noise_schedule\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkaras_ve_schedule\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/persist/FlaxDiff/flaxdiff/trainer/diffusion_trainer.py:361\u001b[39m, in \u001b[36mDiffusionTrainer.fit\u001b[39m\u001b[34m(self, data, training_steps_per_epoch, epochs, val_steps_per_epoch, sampler_class, sampling_noise_schedule)\u001b[39m\n\u001b[32m    356\u001b[39m local_batch_size = data[\u001b[33m'\u001b[39m\u001b[33mlocal_batch_size\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    357\u001b[39m validation_step_args = {\n\u001b[32m    358\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msampler_class\u001b[39m\u001b[33m\"\u001b[39m: sampler_class,\n\u001b[32m    359\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msampling_noise_schedule\u001b[39m\u001b[33m\"\u001b[39m: sampling_noise_schedule,\n\u001b[32m    360\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m361\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_steps_per_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_steps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_step_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbatch_size\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_batch_size\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_steps_per_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_steps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_step_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_step_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/persist/FlaxDiff/flaxdiff/trainer/simple_trainer.py:526\u001b[39m, in \u001b[36mSimpleTrainer.fit\u001b[39m\u001b[34m(self, data, train_steps_per_epoch, epochs, train_step_args, val_steps_per_epoch, validation_step_args)\u001b[39m\n\u001b[32m    523\u001b[39m start_time = time.time()\n\u001b[32m    524\u001b[39m epoch_loss = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m epoch_loss, current_step, train_state, rng_state = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_steps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlatest_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrng_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[38;5;28mprint\u001b[39m(colored(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch done on process index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprocess_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, PROCESS_COLOR_MAP[process_index]))\n\u001b[32m    536\u001b[39m \u001b[38;5;28mself\u001b[39m.latest_step = current_step\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/persist/FlaxDiff/flaxdiff/trainer/simple_trainer.py:438\u001b[39m, in \u001b[36mSimpleTrainer.train_loop\u001b[39m\u001b[34m(self, train_state, train_step_fn, train_ds, train_steps_per_epoch, current_step, rng_state)\u001b[39m\n\u001b[32m    434\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining started for process index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprocess_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m at step \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_step\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    436\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.distributed_training:\n\u001b[32m    437\u001b[39m     \u001b[38;5;66;03m# loss = jax.experimental.multihost_utils.process_allgather(loss)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m438\u001b[39m     loss = \u001b[43mjnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Just to make sure its a scaler value\u001b[39;00m\n\u001b[32m    440\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m loss <= \u001b[32m1e-8\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m jnp.isnan(loss) \u001b[38;5;129;01mor\u001b[39;00m jnp.isinf(loss):\n\u001b[32m    441\u001b[39m     \u001b[38;5;66;03m# If the loss is too low or NaN/Inf, log the issue and attempt recovery\u001b[39;00m\n\u001b[32m    442\u001b[39m     \u001b[38;5;28mprint\u001b[39m(colored(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAbnormal loss at step \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_step\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mred\u001b[39m\u001b[33m'\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/jax/_src/numpy/reductions.py:803\u001b[39m, in \u001b[36mmean\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, where)\u001b[39m\n\u001b[32m    799\u001b[39m     size *= maybe_named_axis(a, \u001b[38;5;28;01mlambda\u001b[39;00m i: a_shape[i], \u001b[38;5;28;01mlambda\u001b[39;00m name: lax.psum(\u001b[32m1\u001b[39m, name))\n\u001b[32m    800\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m size\n\u001b[32m--> \u001b[39m\u001b[32m803\u001b[39m \u001b[38;5;129m@export\u001b[39m\n\u001b[32m    804\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmean\u001b[39m(a: ArrayLike, axis: Axis = \u001b[38;5;28;01mNone\u001b[39;00m, dtype: DTypeLike | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    805\u001b[39m          out: \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, keepdims: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m, *,\n\u001b[32m    806\u001b[39m          where: ArrayLike | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m) -> Array:\n\u001b[32m    807\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Return the mean of array elements along a given axis.\u001b[39;00m\n\u001b[32m    808\u001b[39m \n\u001b[32m    809\u001b[39m \u001b[33;03m  JAX implementation of :func:`numpy.mean`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    865\u001b[39m \u001b[33;03m           [6. ]], dtype=float32)\u001b[39;00m\n\u001b[32m    866\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m    867\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m _mean(a, _ensure_optional_axes(axis), dtype, out, keepdims,\n\u001b[32m    868\u001b[39m                where=where, upcast_f16_for_computation=(dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f734c1c4290>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f726c109890, execution_count=5 error_before_exec=None error_in_exec= info=<ExecutionInfo object at 7f70ac1bd0d0, raw_cell=\"# Train the model\n",
      "final_state = trainer.fit(data, ..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://ssh-remote%2Btpu-v4-8/home/mrwhite0racle/persist/FlaxDiff/prototype_general_pipeline.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "MailboxClosedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMailboxClosedError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:543\u001b[39m, in \u001b[36m_WandbInit._pause_backend\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    541\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.notebook.save_ipynb():  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    542\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.run \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m     res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    544\u001b[39m     \u001b[38;5;28mself\u001b[39m._logger.info(\u001b[33m\"\u001b[39m\u001b[33msaved code: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, res)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    545\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.backend.interface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:435\u001b[39m, in \u001b[36m_run_decorator._noop_on_finish.<locals>.decorator_fn.<locals>.wrapper_fn\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    432\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    433\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper_fn\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[38;5;28mtype\u001b[39m[Run], *args: Any, **kwargs: Any) -> Any:\n\u001b[32m    434\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_is_finished\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m435\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    437\u001b[39m     default_message = (\n\u001b[32m    438\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRun (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) is finished. The call to `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` will be ignored. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    439\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPlease make sure that you are using an active run.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    440\u001b[39m     )\n\u001b[32m    441\u001b[39m     resolved_message = message \u001b[38;5;129;01mor\u001b[39;00m default_message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:387\u001b[39m, in \u001b[36m_log_to_run.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    384\u001b[39m     run_id = \u001b[38;5;28mself\u001b[39m._attach_id\n\u001b[32m    386\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m wb_logging.log_to_run(run_id):\n\u001b[32m--> \u001b[39m\u001b[32m387\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:425\u001b[39m, in \u001b[36m_run_decorator._attach.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    423\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    424\u001b[39m     \u001b[38;5;28mcls\u001b[39m._is_attaching = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m425\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:1147\u001b[39m, in \u001b[36mRun.log_code\u001b[39m\u001b[34m(self, root, name, include_fn, exclude_fn)\u001b[39m\n\u001b[32m   1142\u001b[39m     wandb.termwarn(\n\u001b[32m   1143\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo relevant files were detected in the specified directory. No code will be logged to your run.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1144\u001b[39m     )\n\u001b[32m   1145\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1147\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_log_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mart\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:3351\u001b[39m, in \u001b[36mRun._log_artifact\u001b[39m\u001b[34m(self, artifact_or_path, name, type, aliases, tags, distributed_id, finalize, is_user_created, use_after_commit)\u001b[39m\n\u001b[32m   3349\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.interface:\n\u001b[32m   3350\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._settings._offline:\n\u001b[32m-> \u001b[39m\u001b[32m3351\u001b[39m         handle = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backend\u001b[49m\u001b[43m.\u001b[49m\u001b[43minterface\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeliver_artifact\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3352\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3353\u001b[39m \u001b[43m            \u001b[49m\u001b[43martifact\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3354\u001b[39m \u001b[43m            \u001b[49m\u001b[43maliases\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3355\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3356\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3357\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfinalize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfinalize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3358\u001b[39m \u001b[43m            \u001b[49m\u001b[43mis_user_created\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_user_created\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3359\u001b[39m \u001b[43m            \u001b[49m\u001b[43muse_after_commit\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_after_commit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3360\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3361\u001b[39m         artifact._set_save_handle(handle, \u001b[38;5;28mself\u001b[39m._public_api().client)\n\u001b[32m   3362\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/wandb/sdk/interface/interface.py:589\u001b[39m, in \u001b[36mInterfaceBase.deliver_artifact\u001b[39m\u001b[34m(self, run, artifact, aliases, tags, history_step, is_user_created, use_after_commit, finalize)\u001b[39m\n\u001b[32m    587\u001b[39m     log_artifact.history_step = history_step\n\u001b[32m    588\u001b[39m log_artifact.staging_dir = get_staging_dir()\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_deliver_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_artifact\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py:339\u001b[39m, in \u001b[36mInterfaceShared._deliver_artifact\u001b[39m\u001b[34m(self, log_artifact)\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_deliver_artifact\u001b[39m(\n\u001b[32m    335\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    336\u001b[39m     log_artifact: pb.LogArtifactRequest,\n\u001b[32m    337\u001b[39m ) -> MailboxHandle[pb.Result]:\n\u001b[32m    338\u001b[39m     rec = \u001b[38;5;28mself\u001b[39m._make_request(log_artifact=log_artifact)\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_deliver_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py:389\u001b[39m, in \u001b[36mInterfaceShared._deliver_record\u001b[39m\u001b[34m(self, record)\u001b[39m\n\u001b[32m    386\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_deliver_record\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: pb.Record) -> MailboxHandle[pb.Result]:\n\u001b[32m    387\u001b[39m     mailbox = \u001b[38;5;28mself\u001b[39m._get_mailbox()\n\u001b[32m--> \u001b[39m\u001b[32m389\u001b[39m     handle = \u001b[43mmailbox\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequire_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    390\u001b[39m     \u001b[38;5;28mself\u001b[39m._publish(record)\n\u001b[32m    392\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle.map(\u001b[38;5;28;01mlambda\u001b[39;00m resp: resp.result_communicate)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/flaxdiff/lib/python3.11/site-packages/wandb/sdk/mailbox/mailbox.py:68\u001b[39m, in \u001b[36mMailbox.require_response\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._handles_lock:\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._closed:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m MailboxClosedError()\n\u001b[32m     70\u001b[39m     handle = MailboxResponseHandle(address)\n\u001b[32m     71\u001b[39m     \u001b[38;5;28mself\u001b[39m._handles[address] = handle\n",
      "\u001b[31mMailboxClosedError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "final_state = trainer.fit(data, batches, epochs=2000,\n",
    "                          sampler_class=EulerAncestralSampler, sampling_noise_schedule=karas_ve_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def normalizeImage(x): return jax.nn.standardize(x, mean=[127.5], std=[127.5])\n",
    "def denormalizeImage(x): return (x + 1.0) * 127.5\n",
    "\n",
    "\n",
    "def plotImages(imgs, fig_size=(8, 8), dpi=100):\n",
    "    fig = plt.figure(figsize=fig_size, dpi=dpi)\n",
    "    imglen = imgs.shape[0]\n",
    "    for i in range(imglen):\n",
    "        plt.subplot(fig_size[0], fig_size[1], i + 1)\n",
    "        plt.imshow(jnp.astype(denormalizeImage(imgs[i, :, :, :]), jnp.uint8))\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using classifier-free guidance\n"
     ]
    }
   ],
   "source": [
    "sampler = EulerAncestralSampler(\n",
    "    model=trainer.model,\n",
    "    noise_schedule=karas_ve_schedule,\n",
    "    model_output_transform=KarrasPredictionTransform(\n",
    "        sigma_data=karas_ve_schedule.sigma_data),\n",
    "    autoencoder=trainer.autoencoder,\n",
    "    input_config=trainer.input_config,\n",
    "    guidance_scale=3,\n",
    "    timestep_spacing=\"linear\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing raw conditioning inputs to generate model conditioning inputs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:15<00:00, 13.01it/s]\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    'water tulip',\n",
    "    'a water lily',\n",
    "    'a water lily',\n",
    "    'a photo of a rose',\n",
    "    'a photo of a rose',\n",
    "    'a water lily',\n",
    "    'a water lily',\n",
    "    'a photo of a marigold',\n",
    "]\n",
    "images = sampler.generate_samples(\n",
    "    params=trainer.best_state.params,\n",
    "    resolution=IMAGE_SIZE,\n",
    "    num_samples=len(prompts),\n",
    "    sequence_length=None,\n",
    "    diffusion_steps=200,\n",
    "    start_step=1000,\n",
    "    end_step=0,\n",
    "    conditioning=prompts,\n",
    "    # model_conditioning_inputs=(encoded,)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plotImages' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mplotImages\u001b[49m(images, dpi=\u001b[32m500\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'plotImages' is not defined"
     ]
    }
   ],
   "source": [
    "plotImages(images, dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mrwhite0racle/persist/FlaxDiff/checkpoints/general_diffusion_demo_for_inference'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.checkpoint_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/mrwhite0racle/persist/FlaxDiff/checkpoints/general_diffusion_demo_for_inference2/411355)... Done. 8.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to registry at wandb-registry-model/diffusion-oxford_flowers102-res256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Artifact QXJ0aWZhY3Q6MTY2NzkxMDU2OA==>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_registry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m.wandb.run\n",
      "\u001b[31mNameError\u001b[39m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.wandb.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flaxdiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
